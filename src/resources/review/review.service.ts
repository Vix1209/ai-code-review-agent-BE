import { Injectable } from '@nestjs/common';
import { EmbeddingService } from '../embedding/embedding.service';
import { LlmService } from '../llm/llm.service';
import { VectorDbService } from '../vector-db/vector-db.service';
import { DatabaseService } from '../database/database.service';

@Injectable()
export class ReviewService {
  constructor(
    private readonly embeddingService: EmbeddingService,
    private readonly vectorDbService: VectorDbService,
    private readonly llmService: LlmService,
    private readonly databaseService: DatabaseService,
  ) {}

  /**
   * Processes and stores a reference in the vector database
   * @param content - The text content to process
   * @param metadata - Metadata associated with the content
   * @returns Success response
   */
  async processReference(content: string, metadata: Record<string, any>) {
    // Generate embedding for the content
    const embedding = await this.embeddingService.generateEmbedding(content);

    // Store embedding in the vector database
    await this.vectorDbService.upsertEmbedding({
      id: metadata.id || content.slice(0, 10), // Generate a unique ID if none is provided
      values: embedding,
      metadata,
    });

    // Save reference to the database
    await this.databaseService.saveReference(content, embedding, metadata);

    return { success: true, message: 'Reference stored successfully.' };
  }

  /**
   * Generates a review using the LLM based on a prompt and context retrieved from the vector database
   * @param prompt - The user's query or prompt
   * @returns Feedback generated by the LLM
   */
  async generateReview(prompt: string) {
    // Generate embedding for the query prompt
    const queryEmbedding =
      await this.embeddingService.generateEmbedding(prompt);

    // Search for relevant embeddings in the vector database
    const searchResults = await this.vectorDbService.searchEmbedding(
      queryEmbedding,
      3,
    ); // Top 3 matches

    // Combine context from search results
    const context = searchResults
      .map((result) => result.metadata?.content || '')
      .join('\n');

    // Enrich the prompt with retrieved context
    const enrichedPrompt = `${prompt}\n\nContext:\n${context}`;

    // Use the LLM to generate feedback
    const feedbackResponse =
      await this.llmService.generateFeedback(enrichedPrompt);

    if (feedbackResponse) {
      const feedback = feedbackResponse.content || ''; // Ensure feedback is always a string

      // Save review to the database
      await this.databaseService.saveReview(prompt, enrichedPrompt, feedback);

      return { feedback };
    } else {
      return { feedback: 'No feedback available.' };
    }
  }
}
